{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Define ticker symbols for financials, real estate, and consumer goods sectors\n",
        "financials_tickers = ['LLOY.L', 'HSBA.L', 'BARC.L', ...]  # Add or remove ticker symbols as needed\n",
        "real_estate_tickers = ['LAND.L', 'DLN.L', 'BLND.L', ...]  # Add or remove ticker symbols as needed\n",
        "consumer_goods_tickers = ['ULVR.L', 'IMB.L', 'DGE.L', ...]  # Add or remove ticker symbols as needed\n",
        "\n",
        "# Remove any placeholders such as Ellipsis from the lists\n",
        "if Ellipsis in financials_tickers:\n",
        "    financials_tickers.remove(Ellipsis)\n",
        "if Ellipsis in real_estate_tickers:\n",
        "    real_estate_tickers.remove(Ellipsis)\n",
        "if Ellipsis in consumer_goods_tickers:\n",
        "    consumer_goods_tickers.remove(Ellipsis)\n",
        "\n",
        "# Fetch data for each sector in batches\n",
        "financials_data = pd.DataFrame()\n",
        "for ticker in financials_tickers:\n",
        "    data = fetch_stock_data(ticker, start_date, end_date)\n",
        "    if data is not None and not data.empty:\n",
        "        financials_data[ticker] = data['Adj Close']\n",
        "    else:\n",
        "        print(f\"Failed to fetch data for {ticker}\")\n",
        "\n",
        "# Repeat the process for real estate and consumer goods sectors\n",
        "\n",
        "# Save or process the fetched data\n",
        "financials_data.to_csv('financials_data.csv')\n",
        "# Repeat for real estate and consumer goods sectors\n",
        "\n",
        "# Further processing or analysis as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-0qKAw_PmpP",
        "outputId": "7db91520-742c-4439-8a7f-1c35400873a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all ticker symbols from different sectors into a single list\n",
        "all_tickers = financials_tickers + real_estate_tickers + consumer_goods_tickers\n",
        "\n",
        "# Count the total number of unique ticker symbols\n",
        "total_stocks = len(set(all_tickers))\n",
        "\n",
        "print(\"Total number of stocks:\", total_stocks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qkIzpXEP_0S",
        "outputId": "f4c71829-7794-4d12-9521-89386d635940"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of stocks: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Define a function to get the company name for a given ticker symbol\n",
        "def get_company_name(ticker):\n",
        "    try:\n",
        "        # Create a Ticker object\n",
        "        ticker_obj = yf.Ticker(ticker)\n",
        "        # Get the info dictionary\n",
        "        info = ticker_obj.info\n",
        "        # Extract the company name\n",
        "        company_name = info['longName']\n",
        "        return company_name\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching company name for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Iterate through all ticker symbols and get their corresponding company names\n",
        "stock_names = {}\n",
        "for ticker in all_tickers:\n",
        "    name = get_company_name(ticker)\n",
        "    if name:\n",
        "        stock_names[ticker] = name\n",
        "\n",
        "# Print the ticker symbols and their corresponding company names\n",
        "for ticker, name in stock_names.items():\n",
        "    print(f\"{ticker}: {name}\")\n"
      ],
      "metadata": {
        "id": "ikkiHlT-SmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assume 'X' contains the features and 'y' contains the target variable (returns)\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict returns\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "\n",
        "# Assume 'data' is your DataFrame containing the dataset\n",
        "# 'features' are the columns used as predictors for returns prediction\n",
        "# 'target' is the column containing the returns you want to predict\n",
        "features = ['feature1', 'feature2', ...]  # Replace with actual feature names\n",
        "target = 'returns'  # Replace with actual target variable name\n",
        "\n",
        "# Define X and y\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Assume 'data' is your DataFrame containing the dataset\n",
        "# 'features' are the columns used as predictors for returns prediction\n",
        "# 'target' is the column containing the returns you want to predict\n",
        "features = ['feature1', 'feature2', ...]  # Replace with actual feature names\n",
        "target = 'returns'  # Replace with actual target variable name\n",
        "\n",
        "# Define X and y\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Now you can proceed with splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "JGD4PBYpQb5z",
        "outputId": "b85b24ef-8676-4626-d0da-3e60399a8a65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-cd92bab5488b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assume 'X' contains the features and 'y' contains the target variable (returns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Initialize and train the linear regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Define a function to get the company name for a given ticker symbol\n",
        "def get_company_name(ticker):\n",
        "    try:\n",
        "        # Create a Ticker object\n",
        "        ticker_obj = yf.Ticker(ticker)\n",
        "        # Get the info dictionary\n",
        "        info = ticker_obj.info\n",
        "        # Extract the company name\n",
        "        company_name = info['longName']\n",
        "        return company_name\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching company name for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Iterate through all ticker symbols and get their corresponding company names\n",
        "stock_names = {}\n",
        "for ticker in all_tickers:\n",
        "    name = get_company_name(ticker)\n",
        "    if name:\n",
        "        stock_names[ticker] = name\n",
        "\n",
        "# Print the ticker symbols and their corresponding company names\n",
        "for ticker, name in stock_names.items():\n",
        "    print(f\"{ticker}: {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwvHXS5SSqSv",
        "outputId": "afbc2a6a-42e9-4cdb-cd4a-1ccc7dfd8179"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLOY.L: Lloyds Banking Group plc\n",
            "HSBA.L: HSBC Holdings plc\n",
            "BARC.L: Barclays PLC\n",
            "LAND.L: Land Securities Group Plc\n",
            "DLN.L: Derwent London Plc\n",
            "BLND.L: British Land Company PLC\n",
            "ULVR.L: Unilever PLC\n",
            "IMB.L: Imperial Brands PLC\n",
            "DGE.L: Diageo plc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame with mock data\n",
        "data = {\n",
        "    'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04'],\n",
        "    'Open': [100.0, 101.0, 102.0, 103.0],\n",
        "    'High': [105.0, 106.0, 107.0, 108.0],\n",
        "    'Low': [98.0, 99.0, 100.0, 101.0],\n",
        "    'Close': [102.0, 104.0, 106.0, 108.0],\n",
        "    'Volume': [100000, 110000, 120000, 130000]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Now, you can proceed with the rest of the code using 'df'\n"
      ],
      "metadata": {
        "id": "oRB7LzxSUQNg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with historical stock price data\n",
        "# Ensure the DataFrame contains features and target variable (e.g., 'Close' price)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop(['Close'], axis=1)\n",
        "y = df['Close']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "print(\"Random Forest MAE:\", rf_mae)\n",
        "\n",
        "# Deep Learning Model (LSTM)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions using the LSTM model\n",
        "lstm_pred = lstm_model.predict(X_test_reshaped)\n",
        "lstm_pred = lstm_pred.reshape(-1)  # Reshape predictions to match y_test shape\n",
        "\n",
        "# Calculate MAE for LSTM predictions\n",
        "lstm_mae = mean_absolute_error(y_test, lstm_pred)\n",
        "print(\"LSTM MAE:\", lstm_mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "nR2rDeM8UV3r",
        "outputId": "37a5acdb-44e5-4bf5-a22c-e0b11477ff6f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: '2022-01-04'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b9b93c1c2839>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Random Forest Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mrf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mrf_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2022-01-04'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Date' column from the features (X) before splitting the data\n",
        "X = df.drop(['Date', 'Close'], axis=1)  # Drop both 'Date' and 'Close' columns\n",
        "y = df['Close']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "BjqEEigPUbwq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "print(\"Random Forest MAE:\", rf_mae)\n",
        "\n",
        "# Deep Learning Model (LSTM)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions using the LSTM model\n",
        "lstm_pred = lstm_model.predict(X_test_reshaped)\n",
        "lstm_pred = lstm_pred.reshape(-1)  # Reshape predictions to match y_test shape\n",
        "\n",
        "# Calculate MAE for LSTM predictions\n",
        "lstm_mae = mean_absolute_error(y_test, lstm_pred)\n",
        "print(\"LSTM MAE:\", lstm_mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuYfThj3Ul83",
        "outputId": "9ebf6467-5426-4cb9-f6ca-e843717b85b5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MAE: 0.5799999999999983\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: 11098.1289\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11095.8018\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11093.4678\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11091.1240\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11088.7695\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11086.4062\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11084.0312\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11081.6416\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11079.2422\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11076.8252\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11074.3955\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11071.9502\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11069.4883\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11067.0107\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11064.5127\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 11061.9990\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11059.4639\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11056.9072\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11054.3311\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11051.7305\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11049.1064\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11046.4580\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 11043.7842\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11041.0830\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11038.3545\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11035.5977\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11032.8096\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11029.9912\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11027.1406\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 11024.2549\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11021.3359\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11018.3818\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11015.3916\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11012.3623\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11009.2969\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11006.1904\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11003.0430\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10999.8545\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10996.6221\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10993.3477\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10990.0283\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10986.6641\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10983.2529\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10979.7930\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10976.2861\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10972.7295\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10969.1240\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10965.4658\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10961.7578\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10957.9961\n",
            "1/1 [==============================] - 1s 662ms/step\n",
            "LSTM MAE: 103.52021798491478\n"
          ]
        }
      ]
    }
  ]
}